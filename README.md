# Speech Emotion Recognition

## ğŸ“Œ Project Overview
This project is a **Speech Emotion Recognition** system that processes audio recordings to classify emotions. It utilizes deep learning techniques trained on the **TESS (Toronto Emotional Speech Set) dataset** and provides real-time analysis for both **recorded and uploaded audio files**.

## ğŸ“‚ Folder Structure
```
Speech_Emotion_Recognition/
â”‚â”€â”€ dataset/                     # Store audio files for training  
â”‚   â”œâ”€â”€ TESS/                    # Contains the TESS dataset  
â”‚â”€â”€ models/                       # Trained model & class labels  
â”‚   â”œâ”€â”€ trained_model.h5          # Pre-trained emotion recognition model  
â”‚   â”œâ”€â”€ class_labels.json         # Mapping of class labels  
â”‚â”€â”€ utils/                        # Helper scripts  
â”‚   â”œâ”€â”€ preprocess.py             # Feature extraction functions  
â”‚   â”œâ”€â”€ predict.py                # Prediction logic  
â”‚â”€â”€ notebooks/                    # Jupyter notebooks  
â”‚   â”œâ”€â”€ Speech_emotion_recognition_project.ipynb  # Model training/testing notebook  
â”‚â”€â”€ env/                          # Python virtual environment  
â”‚â”€â”€ recordings/                   # Stores recorded audio files  
â”‚â”€â”€ uploaded_recordings/          # Stores uploaded audio files  
â”‚â”€â”€ app.py                        # Main Flask application  
â”‚â”€â”€ requirements.txt              # Python dependencies  
â”‚â”€â”€ frontend/                     # React Frontend  
â”‚   â”œâ”€â”€ public/                    # Static assets (index.html, icons, etc.)  
â”‚   â”œâ”€â”€ src/                       # React source code  
â”‚   â”‚   â”œâ”€â”€ components/            # React components  
â”‚   â”‚   â”œâ”€â”€ App.js                 # Main React component  
â”‚   â”‚   â”œâ”€â”€ index.js               # Entry point for React app  
â”‚   â”‚   â”œâ”€â”€ App.css                # Global styles  
â”‚   â”œâ”€â”€ package.json               # React dependencies & scripts  
â”‚â”€â”€ README.md                      # Project documentation  
```

## ğŸ› ï¸ Tech Stack
### **Backend**
- Python
- Flask
- TensorFlow/Keras (for deep learning model)
- Librosa (for audio feature extraction)

### **Frontend**
- React.js
- HTML/CSS
- JavaScript

## ğŸ”¹ Features
âœ… **Real-time Emotion Detection** â€“ Supports live recordings and file uploads  
âœ… **Deep Learning-Based Prediction** â€“ Uses a pre-trained model on the TESS dataset  
âœ… **Interactive Frontend** â€“ User-friendly interface for recording and uploading files  
âœ… **Flask API** â€“ Backend for processing and predicting emotions from audio files  

## ğŸš€ How to Run the Project
### 1ï¸âƒ£ Clone the Repository
```sh
git clone https://github.com/Utkgitdev-07/Speech-Emotion-Recognition.git
cd Speech-Emotion-Recognition
```

### 2ï¸âƒ£ Install Dependencies
#### ğŸ”¹ Backend

**Create a Virtual Environment:**

Open your terminal/command prompt and navigate to the project folder. Then, create and activate a virtual environment:
```sh
python -m venv venv      # Create a virtual environment
source venv/bin/activate # For macOS/Linux
venv\Scripts\activate    # For Windows
```
Install Requirements
```sh
pip install -r requirements.txt
```

#### ğŸ”¹ Frontend
```sh
cd frontend
npm install
```

### 3ï¸âƒ£ Build and Run the Application
#### ğŸ”¹ Build Frontend
Run the following command inside the frontend directory to create a production-ready build
```sh
cd frontend
npm run build
```
This will generate a build/ folder inside frontend/.

#### ğŸ”¹ Start Backend Server
Navigate to the project root and run:
```sh
python app.py
```
This will start the Flask server, which serves the React frontend and provides the API for emotion detection.

#### ğŸ”¹ Access the Application

Once the Flask server is running, open your browser and visit:
```sh
http://127.0.0.1:5000
```
The frontend will be available, allowing you to record/upload audio and get emotion predictions.

## ğŸ“Š Dataset Information
- **Dataset Name**: Toronto Emotional Speech Set (TESS)
- **Total Samples**: ~2,800 recordings
- **Emotions Covered**:
  - Angry
  - Disgust
  - Fear
  - Happy
  - Neutral
  - Pleasant Surprise
  - Sad
 
## Notes

 - Ensure you have Python and Node.js installed.

 - The trained model (trained_model.h5) should be placed in the models/ directory.

 - Flask automatically serves the built frontend from frontend/build/.

## ğŸ“© Contributing
If you'd like to contribute to this project, feel free to fork the repository, create a feature branch, and submit a pull request! ğŸ˜Š

## ğŸ“œ License
This project is licensed under the **MIT License**.

---
Made with â¤ï¸ by [Utkarsh Yadav](https://github.com/Utkgitdev-07) ğŸš€

